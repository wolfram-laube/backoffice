{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ§ª NSAI Experiment Notebook\n",
    "\n",
    "**Neurosymbolic Runner Selection â€” A/B Comparison & Analysis**\n",
    "\n",
    "| Version | Date | Author |\n",
    "|---------|------|--------|\n",
    "| 0.3.0 | 2026-02-06 | Wolfram Laube |\n",
    "\n",
    "This notebook runs reproducible experiments comparing three runner selection strategies:\n",
    "\n",
    "1. **Rule-Based** â€” always pick the first feasible runner (static baseline)\n",
    "2. **Pure MAB** â€” UCB1 over all runners, no constraint filtering\n",
    "3. **NSAI** â€” CSP filter â†’ UCB1 (our neurosymbolic approach)\n",
    "\n",
    "Metrics: cumulative reward, regret, convergence speed, selection distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import math, random, time\n",
    "import json\n",
    "from collections import Counter, defaultdict\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "# Ensure nsai is importable\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "if 'google.colab' in sys.modules:\n",
    "    sys.path.insert(0, '/content')\n",
    "\n",
    "from nsai import NeurosymbolicBandit, __version__\n",
    "from nsai.ontology import create_blauweiss_ontology\n",
    "\n",
    "print(f'NSAI v{__version__}')\n",
    "print(f'Runners: {list(create_blauweiss_ontology().runners.keys())}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Ground Truth Definition\n",
    "\n",
    "We simulate job execution with known per-runner success probabilities and durations.\n",
    "This lets us compute **optimal reward** and therefore **regret**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ground truth: success probability per runner per job type\n",
    "GROUND_TRUTH = {\n",
    "    'docker-any': {\n",
    "        'gitlab-runner-nordic':     {'p_success': 0.96, 'avg_duration': 18.0, 'cost': 0.01},\n",
    "        'Mac Docker Runner':        {'p_success': 0.92, 'avg_duration': 25.0, 'cost': 0.00},\n",
    "        'Mac2 Docker Runner':       {'p_success': 0.85, 'avg_duration': 35.0, 'cost': 0.00},\n",
    "        'Linux Yoga Docker Runner': {'p_success': 0.95, 'avg_duration': 15.0, 'cost': 0.00},\n",
    "    },\n",
    "    'gcp': {\n",
    "        'gitlab-runner-nordic':     {'p_success': 0.96, 'avg_duration': 18.0, 'cost': 0.01},\n",
    "        'Mac Docker Runner':        {'p_success': 0.00, 'avg_duration': 999,  'cost': 0.00},\n",
    "        'Mac2 Docker Runner':       {'p_success': 0.00, 'avg_duration': 999,  'cost': 0.00},\n",
    "        'Linux Yoga Docker Runner': {'p_success': 0.00, 'avg_duration': 999,  'cost': 0.00},\n",
    "    },\n",
    "}\n",
    "\n",
    "def simulate_job(runner: str, job_type: str, rng: random.Random) -> Tuple[bool, float]:\n",
    "    \"\"\"Simulate a job execution. Returns (success, duration_seconds).\"\"\"\n",
    "    profile = GROUND_TRUTH[job_type].get(runner, {'p_success': 0.0, 'avg_duration': 60.0})\n",
    "    success = rng.random() < profile['p_success']\n",
    "    duration = max(5.0, rng.gauss(profile['avg_duration'], profile['avg_duration'] * 0.2))\n",
    "    if not success:\n",
    "        duration = max(duration, rng.gauss(60.0, 10.0))  # failures take longer\n",
    "    return success, duration\n",
    "\n",
    "def compute_reward(success: bool, duration: float, cost_per_min: float = 0.0) -> float:\n",
    "    \"\"\"Reward function matching NSAI/MAB.\"\"\"\n",
    "    if not success:\n",
    "        return 0.0\n",
    "    dur_min = duration / 60.0\n",
    "    cost_penalty = cost_per_min * dur_min\n",
    "    return 1.0 / (dur_min + cost_penalty + 0.1)\n",
    "\n",
    "# Optimal runner for docker-any (highest expected reward)\n",
    "for runner, prof in GROUND_TRUTH['docker-any'].items():\n",
    "    expected = prof['p_success'] * (1.0 / (prof['avg_duration']/60 + prof['cost'] * prof['avg_duration']/60 + 0.1))\n",
    "    print(f'{runner:30} E[reward] = {expected:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Strategy Implementations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RuleBasedStrategy:\n",
    "    \"\"\"Always picks the first online runner (static baseline).\"\"\"\n",
    "    def __init__(self):\n",
    "        self.name = 'Rule-Based'\n",
    "        self._default = 'gitlab-runner-nordic'\n",
    "    \n",
    "    def select(self, job_type: str) -> str:\n",
    "        return self._default\n",
    "    \n",
    "    def update(self, runner, success, duration, cost=0.0):\n",
    "        pass  # no learning\n",
    "\n",
    "\n",
    "class PureMABStrategy:\n",
    "    \"\"\"UCB1 over ALL runners â€” no symbolic filtering.\"\"\"\n",
    "    def __init__(self, runners: list, c: float = 2.0):\n",
    "        self.name = 'Pure MAB'\n",
    "        self.c = c\n",
    "        self._stats = {r: {'pulls': 0, 'total_reward': 0.0} for r in runners}\n",
    "        self._total = 0\n",
    "    \n",
    "    def select(self, job_type: str) -> str:\n",
    "        # Exploration: try each at least once\n",
    "        for r, s in self._stats.items():\n",
    "            if s['pulls'] == 0:\n",
    "                return r\n",
    "        # UCB1\n",
    "        best, best_ucb = None, -1\n",
    "        for r, s in self._stats.items():\n",
    "            mean = s['total_reward'] / s['pulls']\n",
    "            explore = self.c * math.sqrt(math.log(self._total + 1) / s['pulls'])\n",
    "            ucb = mean + explore\n",
    "            if ucb > best_ucb:\n",
    "                best, best_ucb = r, ucb\n",
    "        return best\n",
    "    \n",
    "    def update(self, runner, success, duration, cost=0.0):\n",
    "        reward = compute_reward(success, duration, cost)\n",
    "        self._stats[runner]['pulls'] += 1\n",
    "        self._stats[runner]['total_reward'] += reward\n",
    "        self._total += 1\n",
    "\n",
    "\n",
    "class NSAIStrategy:\n",
    "    \"\"\"Full NSAI: CSP filter â†’ UCB1.\"\"\"\n",
    "    def __init__(self):\n",
    "        self.name = 'NSAI'\n",
    "        self.nsai = NeurosymbolicBandit.create_default()\n",
    "    \n",
    "    def select(self, job_type: str) -> str:\n",
    "        tags = [job_type] if job_type != 'docker-any' else ['docker-any']\n",
    "        runner, _ = self.nsai.select_runner({'tags': tags})\n",
    "        return runner or 'gitlab-runner-nordic'\n",
    "    \n",
    "    def update(self, runner, success, duration, cost=0.0):\n",
    "        self.nsai.update(runner, success, duration, cost)\n",
    "\n",
    "print('Strategies defined âœ“')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Run Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(n_rounds=200, seed=42, job_type='docker-any'):\n",
    "    \"\"\"Run A/B experiment and return per-round results.\"\"\"\n",
    "    rng = random.Random(seed)\n",
    "    runners = list(GROUND_TRUTH[job_type].keys())\n",
    "    \n",
    "    strategies = [\n",
    "        RuleBasedStrategy(),\n",
    "        PureMABStrategy(runners),\n",
    "        NSAIStrategy(),\n",
    "    ]\n",
    "    \n",
    "    # Compute optimal expected reward for regret\n",
    "    best_expected = max(\n",
    "        p['p_success'] * compute_reward(True, p['avg_duration'], p['cost'])\n",
    "        for p in GROUND_TRUTH[job_type].values()\n",
    "        if p['p_success'] > 0\n",
    "    )\n",
    "    \n",
    "    results = {s.name: {\n",
    "        'rewards': [], 'cum_reward': [], 'regret': [],\n",
    "        'cum_regret': [], 'selections': []\n",
    "    } for s in strategies}\n",
    "    \n",
    "    for t in range(n_rounds):\n",
    "        for strategy in strategies:\n",
    "            r = results[strategy.name]\n",
    "            \n",
    "            runner = strategy.select(job_type)\n",
    "            success, duration = simulate_job(runner, job_type, rng)\n",
    "            cost = GROUND_TRUTH[job_type].get(runner, {}).get('cost', 0.0)\n",
    "            reward = compute_reward(success, duration, cost)\n",
    "            \n",
    "            strategy.update(runner, success, duration, cost)\n",
    "            \n",
    "            r['rewards'].append(reward)\n",
    "            r['cum_reward'].append(sum(r['rewards']))\n",
    "            r['regret'].append(best_expected - reward)\n",
    "            r['cum_regret'].append(sum(r['regret']))\n",
    "            r['selections'].append(runner)\n",
    "    \n",
    "    return results\n",
    "\n",
    "results = run_experiment(n_rounds=300, seed=42)\n",
    "print(f'Experiment complete: 300 rounds Ã— 3 strategies')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Results: Cumulative Reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text-based results (works without matplotlib)\n",
    "print('=== Cumulative Reward (after 300 rounds) ===\\n')\n",
    "for name, r in sorted(results.items(), key=lambda x: -x[1]['cum_reward'][-1]):\n",
    "    total = r['cum_reward'][-1]\n",
    "    avg = total / len(r['rewards'])\n",
    "    bar = 'â–ˆ' * int(total / 5)\n",
    "    print(f'{name:15} {total:7.1f}  (avg {avg:.3f})  {bar}')\n",
    "\n",
    "print('\\n=== Cumulative Regret (lower is better) ===\\n')\n",
    "for name, r in sorted(results.items(), key=lambda x: x[1]['cum_regret'][-1]):\n",
    "    total = r['cum_regret'][-1]\n",
    "    bar = 'â–‘' * int(total / 2)\n",
    "    print(f'{name:15} {total:7.1f}  {bar}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Results: Selection Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('=== Runner Selection Distribution ===\\n')\n",
    "runners_short = {\n",
    "    'gitlab-runner-nordic': 'nordic',\n",
    "    'Mac Docker Runner': 'mac',\n",
    "    'Mac2 Docker Runner': 'mac2',\n",
    "    'Linux Yoga Docker Runner': 'linux',\n",
    "}\n",
    "\n",
    "for name, r in results.items():\n",
    "    counts = Counter(r['selections'])\n",
    "    total = len(r['selections'])\n",
    "    print(f'--- {name} ---')\n",
    "    for runner in GROUND_TRUTH['docker-any']:\n",
    "        n = counts.get(runner, 0)\n",
    "        pct = n / total * 100\n",
    "        bar = 'â–“' * int(pct / 2)\n",
    "        short = runners_short.get(runner, runner[:10])\n",
    "        print(f'  {short:8} {n:4}/{total}  ({pct:5.1f}%)  {bar}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Results: Convergence Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convergence_round(selections: list, optimal: str, window: int = 20, threshold: float = 0.7) -> int:\n",
    "    \"\"\"Find the round where strategy converges to selecting optimal runner.\"\"\"\n",
    "    for i in range(window, len(selections)):\n",
    "        recent = selections[i-window:i]\n",
    "        if recent.count(optimal) / window >= threshold:\n",
    "            return i - window\n",
    "    return -1  # didn't converge\n",
    "\n",
    "# Optimal runner for docker-any is Linux Yoga (highest reward:cost ratio)\n",
    "optimal = 'Linux Yoga Docker Runner'\n",
    "\n",
    "print(f'=== Convergence to Optimal Runner ({runners_short[optimal]}) ===\\n')\n",
    "print(f'Criterion: â‰¥70% selection rate in rolling window of 20\\n')\n",
    "\n",
    "for name, r in results.items():\n",
    "    conv = convergence_round(r['selections'], optimal)\n",
    "    if conv >= 0:\n",
    "        print(f'{name:15} converged at round {conv}')\n",
    "    else:\n",
    "        pct = Counter(r['selections']).get(optimal, 0) / len(r['selections']) * 100\n",
    "        print(f'{name:15} did not converge ({pct:.0f}% overall)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Regret Curve (ASCII)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ascii_plot(series_dict: dict, title: str, width: int = 70, height: int = 20):\n",
    "    \"\"\"Simple ASCII line chart.\"\"\"\n",
    "    all_vals = [v for vals in series_dict.values() for v in vals]\n",
    "    y_min, y_max = min(all_vals), max(all_vals)\n",
    "    if y_max == y_min:\n",
    "        y_max = y_min + 1\n",
    "    x_len = max(len(v) for v in series_dict.values())\n",
    "    \n",
    "    symbols = {'Rule-Based': '.', 'Pure MAB': '+', 'NSAI': '*'}\n",
    "    \n",
    "    print(f'\\n{title}')\n",
    "    print('â”€' * (width + 10))\n",
    "    \n",
    "    grid = [[' '] * width for _ in range(height)]\n",
    "    \n",
    "    for name, vals in series_dict.items():\n",
    "        sym = symbols.get(name, '?')\n",
    "        step = max(1, len(vals) // width)\n",
    "        for xi in range(0, min(len(vals), width * step), step):\n",
    "            col = xi // step\n",
    "            if col >= width:\n",
    "                break\n",
    "            row = int((vals[xi] - y_min) / (y_max - y_min) * (height - 1))\n",
    "            row = height - 1 - row  # invert y\n",
    "            grid[row][col] = sym\n",
    "    \n",
    "    for i, row in enumerate(grid):\n",
    "        y_val = y_max - (y_max - y_min) * i / (height - 1)\n",
    "        print(f'{y_val:7.1f} â”‚{\".\".join(row)}')\n",
    "    \n",
    "    print(f'        â””{\"â”€\" * width}')\n",
    "    print(f'         0{\" \" * (width-6)}round {x_len}')\n",
    "    print(f'\\n  Legend: ', end='')\n",
    "    for name, sym in symbols.items():\n",
    "        print(f'{sym}={name}  ', end='')\n",
    "    print()\n",
    "\n",
    "ascii_plot(\n",
    "    {name: r['cum_regret'] for name, r in results.items()},\n",
    "    'Cumulative Regret (lower is better)'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Live MAB Service Sync"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "\n",
    "MAB_URL = 'https://runner-bandit-m5cziijwqa-lz.a.run.app'\n",
    "\n",
    "try:\n",
    "    with urllib.request.urlopen(f'{MAB_URL}/stats', timeout=5) as resp:\n",
    "        live_stats = json.loads(resp.read())\n",
    "    \n",
    "    print(f'MAB Service: {live_stats[\"algorithm\"]}')\n",
    "    print(f'Total observations: {live_stats[\"total_observations\"]}\\n')\n",
    "    \n",
    "    for runner, stats in live_stats.get('runners', {}).items():\n",
    "        print(f'{runner:30} pulls={stats[\"pulls\"]:3}  '\n",
    "              f'success={stats[\"success_rate\"]:.0%}  '\n",
    "              f'avg_dur={stats[\"avg_duration\"]:.1f}s  '\n",
    "              f'reward={stats[\"mean_reward\"]:.3f}')\n",
    "    \n",
    "    # Warm-start NSAI from live data\n",
    "    nsai_live = NeurosymbolicBandit.from_live_service(MAB_URL)\n",
    "    print(f'\\nâœ… NSAI warm-started from live service')\n",
    "    print(f'   Total pulls synced: {nsai_live._total_pulls}')\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f'âš ï¸ MAB service not reachable: {e}')\n",
    "    print('Continuing with cold-start NSAI.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. NSAI Explanation Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create NSAI with some training\n",
    "nsai = NeurosymbolicBandit.create_default()\n",
    "rng = random.Random(42)\n",
    "\n",
    "# Quick training\n",
    "for _ in range(30):\n",
    "    runner, _ = nsai.select_runner({'tags': ['docker-any']})\n",
    "    success, dur = simulate_job(runner, 'docker-any', rng)\n",
    "    nsai.update(runner, success, dur)\n",
    "\n",
    "print('=== Docker Job Selection ===')\n",
    "runner, exp = nsai.select_runner({'tags': ['docker-any']}, job_name='test:unit')\n",
    "print(exp)\n",
    "\n",
    "print('\\n\\n=== GCP-Only Job Selection ===')\n",
    "runner, exp = nsai.select_runner({'tags': ['docker-any', 'gcp']}, job_name='cloud-run:build')\n",
    "print(exp)\n",
    "\n",
    "print('\\n\\n=== Impossible Job ===')\n",
    "runner, exp = nsai.select_runner({'tags': ['gpu', 'arm64']}, job_name='ml:train')\n",
    "print(exp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—')\n",
    "print('â•‘           NSAI Experiment Summary                       â•‘')\n",
    "print('â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£')\n",
    "print(f'â•‘  NSAI Version:      {__version__:>10}                         â•‘')\n",
    "print(f'â•‘  Runners:           {len(create_blauweiss_ontology().runners):>10}                         â•‘')\n",
    "print(f'â•‘  Experiment Rounds: {300:>10}                         â•‘')\n",
    "print('â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£')\n",
    "\n",
    "for name in ['NSAI', 'Pure MAB', 'Rule-Based']:\n",
    "    r = results[name]\n",
    "    cum_r = r['cum_reward'][-1]\n",
    "    cum_reg = r['cum_regret'][-1]\n",
    "    print(f'â•‘  {name:15} reward={cum_r:7.1f}  regret={cum_reg:7.1f}    â•‘')\n",
    "\n",
    "print('â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£')\n",
    "\n",
    "# NSAI advantage\n",
    "nsai_r = results['NSAI']['cum_reward'][-1]\n",
    "rule_r = results['Rule-Based']['cum_reward'][-1]\n",
    "mab_r = results['Pure MAB']['cum_reward'][-1]\n",
    "print(f'â•‘  NSAI vs Rule-Based: {((nsai_r/rule_r - 1)*100):+.1f}% reward              â•‘')\n",
    "print(f'â•‘  NSAI vs Pure MAB:   {((nsai_r/mab_r - 1)*100):+.1f}% reward              â•‘')\n",
    "print('â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
